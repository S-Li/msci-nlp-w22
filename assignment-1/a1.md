main.py takes each entry pos.txt and neg.txt (400,000 lines each) from the Amazon reviews corpus does the following using core Python:
  - filters out punctuation
  - tokenizes each review
  - stop word removal
  - outputs the sentences to appropriate out files (randomly split between training (80%), validation (10%), and test (10%) sets)

out files:
  - out.csv: tokenized sentences with stopwords
  - out_ns.csv: tokenized sentences without stopwords
  - train.csv: training set with stopwords
  - train_ns.csv: training set without stopwords
  - val.csv: validation set with stopwords
  - val_ns.csv: validation set without stopwords
  - test.csv: test set with stopwords
  - test_ns.csv: test set without stopwords
